{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import scipy as sp \n",
    "import scipy.ndimage as spi\n",
    "%matplotlib inline\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = Path('training') \n",
    "validation_data = Path('validation') \n",
    "labels_path = Path('monkey_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_labels = []\n",
    "\n",
    "# Read the file\n",
    "lines = labels_path.read_text().strip().splitlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n0   , alouatta_palliata\\t , mantled_howler                , 131          , 26',\n",
       " 'n1   , erythrocebus_patas\\t , patas_monkey                  , 139          , 28',\n",
       " 'n2   , cacajao_calvus\\t     , bald_uakari                   , 137          , 27',\n",
       " 'n3   , macaca_fuscata\\t     , japanese_macaque              , 152          , 30',\n",
       " 'n4   , cebuella_pygmea\\t     , pygmy_marmoset                , 131          , 26',\n",
       " 'n5   , cebus_capucinus\\t     , white_headed_capuchin         , 141          , 28',\n",
       " 'n6   , mico_argentatus\\t     , silvery_marmoset              , 132          , 26',\n",
       " 'n7   , saimiri_sciureus\\t     , common_squirrel_monkey        , 142          , 28',\n",
       " 'n8   , aotus_nigriceps\\t     , black_headed_night_monkey     , 133          , 27',\n",
       " 'n9   , trachypithecus_johnii , nilgiri_langur                , 132          , 26']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    line = line.split(',')\n",
    "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
    "    line[3], line[4] = int(line[3]), int(line[4])\n",
    "    line = tuple(line)\n",
    "    monkey_labels.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_labels = pd.DataFrame(monkey_labels, columns=['Label', 'Latin Name', 'Common Name','Train Images', 'Validation Images'], index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Latin Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Train Images</th>\n",
       "      <th>Validation Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>alouatta_palliata</td>\n",
       "      <td>mantled_howler</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>erythrocebus_patas</td>\n",
       "      <td>patas_monkey</td>\n",
       "      <td>139</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>cacajao_calvus</td>\n",
       "      <td>bald_uakari</td>\n",
       "      <td>137</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>macaca_fuscata</td>\n",
       "      <td>japanese_macaque</td>\n",
       "      <td>152</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>cebuella_pygmea</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>cebus_capucinus</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "      <td>141</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>mico_argentatus</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>saimiri_sciureus</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "      <td>142</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>aotus_nigriceps</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>trachypithecus_johnii</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label             Latin Name                Common Name  Train Images  \\\n",
       "0    n0      alouatta_palliata             mantled_howler           131   \n",
       "1    n1     erythrocebus_patas               patas_monkey           139   \n",
       "2    n2         cacajao_calvus                bald_uakari           137   \n",
       "3    n3         macaca_fuscata           japanese_macaque           152   \n",
       "4    n4        cebuella_pygmea             pygmy_marmoset           131   \n",
       "5    n5        cebus_capucinus      white_headed_capuchin           141   \n",
       "6    n6        mico_argentatus           silvery_marmoset           132   \n",
       "7    n7       saimiri_sciureus     common_squirrel_monkey           142   \n",
       "8    n8        aotus_nigriceps  black_headed_night_monkey           133   \n",
       "9    n9  trachypithecus_johnii             nilgiri_langur           132   \n",
       "\n",
       "   Validation Images  \n",
       "0                 26  \n",
       "1                 28  \n",
       "2                 27  \n",
       "3                 30  \n",
       "4                 26  \n",
       "5                 28  \n",
       "6                 26  \n",
       "7                 28  \n",
       "8                 27  \n",
       "9                 26  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monkey_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>mantled_howler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>patas_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>bald_uakari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>japanese_macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       name\n",
       "0  n0             mantled_howler\n",
       "1  n1               patas_monkey\n",
       "2  n2                bald_uakari\n",
       "3  n3           japanese_macaque\n",
       "4  n4             pygmy_marmoset\n",
       "5  n5      white_headed_capuchin\n",
       "6  n6           silvery_marmoset\n",
       "7  n7     common_squirrel_monkey\n",
       "8  n8  black_headed_night_monkey\n",
       "9  n9             nilgiri_langur"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.DataFrame()\n",
    "labels[\"id\"] = monkey_labels[\"Label\"].str.strip()\n",
    "labels[\"name\"] = monkey_labels[\"Common Name\"].str.strip()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    n0\n",
       "1    n1\n",
       "2    n2\n",
       "3    n3\n",
       "4    n4\n",
       "5    n5\n",
       "6    n6\n",
       "7    n7\n",
       "8    n8\n",
       "9    n9\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map the labels to integers\n",
    "m_id= labels[\"id\"]\n",
    "m_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir(training_data)\n",
    "for entry in entries:\n",
    "    for f in glob.glob(os.path.join(os.path.join(training_data,entry),\"*.jpg\")):\n",
    "        W = 250.\n",
    "        oriimg = cv2.imread(f,cv2.IMREAD_COLOR)\n",
    "        depth = oriimg.shape\n",
    "        imgScale = W/250\n",
    "        newX,newY = 250*imgScale, 250*imgScale\n",
    "        newimg = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "        cv2.imwrite(f,newimg)        \n",
    "\n",
    "entries2 = os.listdir(validation_data)\n",
    "\n",
    "for entry in entries2:\n",
    "    for f in glob.glob(os.path.join(os.path.join(validation_data,entry),\"*.jpg\")):\n",
    "        W = 250.\n",
    "        oriimg = cv2.imread(f,cv2.IMREAD_COLOR)\n",
    "        depth = oriimg.shape\n",
    "        imgScale = W/250\n",
    "        newX,newY = 250*imgScale, 250*imgScale\n",
    "        newimg = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "        cv2.imwrite(f,newimg)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prepares a random batch from the dataset\n",
    "def load_batch(dataset_df, batch_size = 25):\n",
    "    batch_df = dataset_df.loc[np.random.permutation(np.arange(0,\n",
    "                                                              len(dataset_df)))[:batch_size],:]\n",
    "    return batch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width=250\n",
    "image_height=250\n",
    "batch_size= 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1096 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(training_data, \n",
    "                                                    target_size=(image_width, image_height), \n",
    "                                                    batch_size = batch_size, \n",
    "                                                    shuffle=True, # By shuffling the images we add some randomness and prevent overfitting\n",
    "                                                    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(validation_data, \n",
    "                                                    target_size=(image_width, image_height), \n",
    "                                                    batch_size = batch_size, \n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = 1097\n",
    "validation_samples = 272\n",
    "total_steps = training_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3), pooling=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-5]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7ff3d325e1d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d2ce5e80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d28727f0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7ff3d2967438> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d338bef0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d2e466d8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7ff3d2807b70> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d28168d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d33b82b0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d289fe48> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7ff3d28816d8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d28819b0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d26b54a8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d26cdac8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7ff3d2679240> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d2667e48> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d2693d68> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff3d263d5c0> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7ff3d2659d30> True\n",
      "<keras.layers.pooling.GlobalMaxPooling2D object at 0x7ff3d26599e8> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "transfer_model = Sequential()\n",
    "for layer in model.layers:\n",
    "    transfer_model.add(layer)\n",
    "transfer_model.add(Dense(512, activation=\"relu\"))\n",
    "transfer_model.add(Dropout(0.5))\n",
    "transfer_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 14,982,474\n",
      "Trainable params: 7,347,210\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\n",
    "\n",
    "transfer_model.compile(loss=\"categorical_crossentropy\",\n",
    "                      optimizer=adam,\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/25\n",
      "68/68 [==============================] - 880s 13s/step - loss: 2.0709 - acc: 0.2730 - val_loss: 1.2820 - val_acc: 0.6066\n",
      "Epoch 2/25\n",
      "68/68 [==============================] - 765s 11s/step - loss: 1.2319 - acc: 0.5698 - val_loss: 0.7529 - val_acc: 0.7831\n",
      "Epoch 3/25\n",
      "68/68 [==============================] - 739s 11s/step - loss: 0.7813 - acc: 0.7418 - val_loss: 0.5584 - val_acc: 0.8051\n",
      "Epoch 4/25\n",
      "68/68 [==============================] - 721s 11s/step - loss: 0.5360 - acc: 0.8226 - val_loss: 0.3727 - val_acc: 0.9007\n",
      "Epoch 5/25\n",
      "68/68 [==============================] - 715s 11s/step - loss: 0.4346 - acc: 0.8649 - val_loss: 0.3069 - val_acc: 0.9007\n",
      "Epoch 6/25\n",
      "68/68 [==============================] - 726s 11s/step - loss: 0.3367 - acc: 0.8787 - val_loss: 0.2672 - val_acc: 0.9301\n",
      "Epoch 7/25\n",
      "68/68 [==============================] - 724s 11s/step - loss: 0.3172 - acc: 0.8915 - val_loss: 0.2778 - val_acc: 0.9154\n",
      "Epoch 8/25\n",
      "68/68 [==============================] - 720s 11s/step - loss: 0.2811 - acc: 0.9044 - val_loss: 0.3401 - val_acc: 0.8787\n",
      "Epoch 9/25\n",
      "68/68 [==============================] - 724s 11s/step - loss: 0.2268 - acc: 0.9246 - val_loss: 0.2958 - val_acc: 0.9228\n",
      "Epoch 10/25\n",
      "68/68 [==============================] - 718s 11s/step - loss: 0.2111 - acc: 0.9311 - val_loss: 0.2331 - val_acc: 0.9412\n",
      "Epoch 11/25\n",
      "68/68 [==============================] - 729s 11s/step - loss: 0.1367 - acc: 0.9550 - val_loss: 0.2318 - val_acc: 0.9485\n",
      "Epoch 12/25\n",
      "68/68 [==============================] - 732s 11s/step - loss: 0.1902 - acc: 0.9366 - val_loss: 0.3180 - val_acc: 0.9228\n",
      "Epoch 13/25\n",
      "68/68 [==============================] - 726s 11s/step - loss: 0.1667 - acc: 0.9458 - val_loss: 0.2283 - val_acc: 0.9301\n",
      "Epoch 14/25\n",
      "68/68 [==============================] - 725s 11s/step - loss: 0.0911 - acc: 0.9706 - val_loss: 0.2609 - val_acc: 0.9265\n",
      "Epoch 15/25\n",
      "68/68 [==============================] - 713s 10s/step - loss: 0.0846 - acc: 0.9697 - val_loss: 0.2059 - val_acc: 0.9522\n",
      "Epoch 16/25\n",
      "68/68 [==============================] - 778s 11s/step - loss: 0.1178 - acc: 0.9577 - val_loss: 0.2338 - val_acc: 0.9485\n",
      "Epoch 17/25\n",
      "68/68 [==============================] - 778s 11s/step - loss: 0.0698 - acc: 0.9798 - val_loss: 0.2107 - val_acc: 0.9449\n",
      "Epoch 18/25\n",
      "68/68 [==============================] - 696s 10s/step - loss: 0.0897 - acc: 0.9678 - val_loss: 0.3339 - val_acc: 0.8934\n",
      "Epoch 19/25\n",
      "68/68 [==============================] - 767s 11s/step - loss: 0.1032 - acc: 0.9660 - val_loss: 0.2966 - val_acc: 0.9191\n",
      "Epoch 20/25\n",
      "68/68 [==============================] - 735s 11s/step - loss: 0.1143 - acc: 0.9660 - val_loss: 0.2225 - val_acc: 0.9485\n",
      "Epoch 21/25\n",
      "68/68 [==============================] - 730s 11s/step - loss: 0.0873 - acc: 0.9743 - val_loss: 0.1600 - val_acc: 0.9559\n",
      "Epoch 22/25\n",
      "68/68 [==============================] - 751s 11s/step - loss: 0.0857 - acc: 0.9697 - val_loss: 0.1949 - val_acc: 0.9522\n",
      "Epoch 23/25\n",
      "68/68 [==============================] - 746s 11s/step - loss: 0.0606 - acc: 0.9770 - val_loss: 0.2154 - val_acc: 0.9485\n",
      "Epoch 24/25\n",
      "68/68 [==============================] - 716s 11s/step - loss: 0.0920 - acc: 0.9752 - val_loss: 0.3095 - val_acc: 0.9154\n",
      "Epoch 25/25\n",
      "68/68 [==============================] - 725s 11s/step - loss: 0.0692 - acc: 0.9779 - val_loss: 0.2359 - val_acc: 0.9338\n"
     ]
    }
   ],
   "source": [
    "model_history = transfer_model.fit_generator(train_generator, steps_per_epoch=training_samples // batch_size,\n",
    "                                            epochs=25,\n",
    "                                            validation_data=validation_generator,\n",
    "                                            validation_steps=validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
