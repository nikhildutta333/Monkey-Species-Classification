{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import scipy as sp \n",
    "import scipy.ndimage as spi\n",
    "%matplotlib inline\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = Path('training') \n",
    "validation_data = Path('validation') \n",
    "labels_path = Path('monkey_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_labels = []\n",
    "\n",
    "# Read the file\n",
    "lines = labels_path.read_text().strip().splitlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n0   , alouatta_palliata\\t , mantled_howler                , 131          , 26',\n",
       " 'n1   , erythrocebus_patas\\t , patas_monkey                  , 139          , 28',\n",
       " 'n2   , cacajao_calvus\\t     , bald_uakari                   , 137          , 27',\n",
       " 'n3   , macaca_fuscata\\t     , japanese_macaque              , 152          , 30',\n",
       " 'n4   , cebuella_pygmea\\t     , pygmy_marmoset                , 131          , 26',\n",
       " 'n5   , cebus_capucinus\\t     , white_headed_capuchin         , 141          , 28',\n",
       " 'n6   , mico_argentatus\\t     , silvery_marmoset              , 132          , 26',\n",
       " 'n7   , saimiri_sciureus\\t     , common_squirrel_monkey        , 142          , 28',\n",
       " 'n8   , aotus_nigriceps\\t     , black_headed_night_monkey     , 133          , 27',\n",
       " 'n9   , trachypithecus_johnii , nilgiri_langur                , 132          , 26']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    line = line.split(',')\n",
    "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
    "    line[3], line[4] = int(line[3]), int(line[4])\n",
    "    line = tuple(line)\n",
    "    monkey_labels.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_labels = pd.DataFrame(monkey_labels, columns=['Label', 'Latin Name', 'Common Name','Train Images', 'Validation Images'], index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'Latin Name', 'Common Name', 'Train Images',\n",
       "       'Validation Images'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monkey_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>mantled_howler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>patas_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>bald_uakari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>japanese_macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       name\n",
       "0  n0             mantled_howler\n",
       "1  n1               patas_monkey\n",
       "2  n2                bald_uakari\n",
       "3  n3           japanese_macaque\n",
       "4  n4             pygmy_marmoset\n",
       "5  n5      white_headed_capuchin\n",
       "6  n6           silvery_marmoset\n",
       "7  n7     common_squirrel_monkey\n",
       "8  n8  black_headed_night_monkey\n",
       "9  n9             nilgiri_langur"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.DataFrame()\n",
    "labels[\"id\"] = monkey_labels[\"Label\"].str.strip()\n",
    "labels[\"name\"] = monkey_labels[\"Common Name\"].str.strip()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    n0\n",
       "1    n1\n",
       "2    n2\n",
       "3    n3\n",
       "4    n4\n",
       "5    n5\n",
       "6    n6\n",
       "7    n7\n",
       "8    n8\n",
       "9    n9\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map the labels to integers\n",
    "m_id= labels[\"id\"]\n",
    "m_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir(training_data)\n",
    "for entry in entries:\n",
    "    for f in glob.glob(os.path.join(os.path.join(training_data,entry),\"*.jpg\")):\n",
    "        W = 250.\n",
    "        oriimg = cv2.imread(f,cv2.IMREAD_COLOR)\n",
    "        depth = oriimg.shape\n",
    "        imgScale = W/250\n",
    "        newX,newY = 250*imgScale, 250*imgScale\n",
    "        newimg = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "        cv2.imwrite(f,newimg)        \n",
    "\n",
    "entries2 = os.listdir(validation_data)\n",
    "\n",
    "for entry in entries2:\n",
    "    for f in glob.glob(os.path.join(os.path.join(validation_data,entry),\"*.jpg\")):\n",
    "        W = 250.\n",
    "        oriimg = cv2.imread(f,cv2.IMREAD_COLOR)\n",
    "        depth = oriimg.shape\n",
    "        imgScale = W/250\n",
    "        newX,newY = 250*imgScale, 250*imgScale\n",
    "        newimg = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "        cv2.imwrite(f,newimg)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prepares a random batch from the dataset\n",
    "def load_batch(dataset_df, batch_size = 25):\n",
    "    batch_df = dataset_df.loc[np.random.permutation(np.arange(0,\n",
    "                                                              len(dataset_df)))[:batch_size],:]\n",
    "    return batch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots sample images in specified size and in defined grid\n",
    "def plot_batch(images_df, grid_width, grid_height, im_scale_x, im_scale_y):\n",
    "    f, ax = plt.subplots(grid_width, grid_height)\n",
    "    f.set_size_inches(12, 12)\n",
    "    \n",
    "    img_idx = 0\n",
    "    for i in range(0, grid_width):\n",
    "        for j in range(0, grid_height):\n",
    "            ax[i][j].axis('off')\n",
    "            ax[i][j].set_title(images_df.iloc[img_idx]['breed'][:10])\n",
    "            ax[i][j].imshow(sp.misc.imresize(spi.imread(os.path.join(training_data,rand(m_id)) + images_df.iloc[img_idx]['id']+'.jpg'),\n",
    "                                             (im_scale_x,im_scale_y)))\n",
    "            img_idx += 1\n",
    "            \n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0.25)\n",
    "\n",
    "# load dataset and visualize sample data\n",
    "dataset_df = pd.read_csv(LABEL_PATH)\n",
    "batch_df = load_batch(dataset_df, batch_size=36)\n",
    "plot_batch(batch_df, grid_width=6, grid_height=6,\n",
    "           im_scale_x=64, im_scale_y=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width=250\n",
    "image_height=250\n",
    "batch_size= 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1096 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(training_data, \n",
    "                                                    target_size=(image_width, image_height), \n",
    "                                                    batch_size = batch_size, \n",
    "                                                    shuffle=True, # By shuffling the images we add some randomness and prevent overfitting\n",
    "                                                    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(validation_data, \n",
    "                                                    target_size=(image_width, image_height), \n",
    "                                                    batch_size = batch_size, \n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = 1097\n",
    "validation_samples = 272\n",
    "total_steps = training_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 111s 2us/step\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3), pooling=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
