{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import scipy as sp \n",
    "import scipy.ndimage as spi\n",
    "%matplotlib inline\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = Path('training') \n",
    "validation_data = Path('validation') \n",
    "labels_path = Path('monkey_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_labels = []\n",
    "\n",
    "# Read the file\n",
    "lines = labels_path.read_text().strip().splitlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n0   , alouatta_palliata\\t , mantled_howler                , 131          , 26',\n",
       " 'n1   , erythrocebus_patas\\t , patas_monkey                  , 139          , 28',\n",
       " 'n2   , cacajao_calvus\\t     , bald_uakari                   , 137          , 27',\n",
       " 'n3   , macaca_fuscata\\t     , japanese_macaque              , 152          , 30',\n",
       " 'n4   , cebuella_pygmea\\t     , pygmy_marmoset                , 131          , 26',\n",
       " 'n5   , cebus_capucinus\\t     , white_headed_capuchin         , 141          , 28',\n",
       " 'n6   , mico_argentatus\\t     , silvery_marmoset              , 132          , 26',\n",
       " 'n7   , saimiri_sciureus\\t     , common_squirrel_monkey        , 142          , 28',\n",
       " 'n8   , aotus_nigriceps\\t     , black_headed_night_monkey     , 133          , 27',\n",
       " 'n9   , trachypithecus_johnii , nilgiri_langur                , 132          , 26']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    line = line.split(',')\n",
    "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
    "    line[3], line[4] = int(line[3]), int(line[4])\n",
    "    line = tuple(line)\n",
    "    monkey_labels.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_labels = pd.DataFrame(monkey_labels, columns=['Label', 'Latin Name', 'Common Name','Train Images', 'Validation Images'], index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Latin Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Train Images</th>\n",
       "      <th>Validation Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>alouatta_palliata</td>\n",
       "      <td>mantled_howler</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>erythrocebus_patas</td>\n",
       "      <td>patas_monkey</td>\n",
       "      <td>139</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>cacajao_calvus</td>\n",
       "      <td>bald_uakari</td>\n",
       "      <td>137</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>macaca_fuscata</td>\n",
       "      <td>japanese_macaque</td>\n",
       "      <td>152</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>cebuella_pygmea</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>cebus_capucinus</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "      <td>141</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>mico_argentatus</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>saimiri_sciureus</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "      <td>142</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>aotus_nigriceps</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>trachypithecus_johnii</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label             Latin Name                Common Name  Train Images  \\\n",
       "0    n0      alouatta_palliata             mantled_howler           131   \n",
       "1    n1     erythrocebus_patas               patas_monkey           139   \n",
       "2    n2         cacajao_calvus                bald_uakari           137   \n",
       "3    n3         macaca_fuscata           japanese_macaque           152   \n",
       "4    n4        cebuella_pygmea             pygmy_marmoset           131   \n",
       "5    n5        cebus_capucinus      white_headed_capuchin           141   \n",
       "6    n6        mico_argentatus           silvery_marmoset           132   \n",
       "7    n7       saimiri_sciureus     common_squirrel_monkey           142   \n",
       "8    n8        aotus_nigriceps  black_headed_night_monkey           133   \n",
       "9    n9  trachypithecus_johnii             nilgiri_langur           132   \n",
       "\n",
       "   Validation Images  \n",
       "0                 26  \n",
       "1                 28  \n",
       "2                 27  \n",
       "3                 30  \n",
       "4                 26  \n",
       "5                 28  \n",
       "6                 26  \n",
       "7                 28  \n",
       "8                 27  \n",
       "9                 26  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monkey_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>mantled_howler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>patas_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>bald_uakari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>japanese_macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       name\n",
       "0  n0             mantled_howler\n",
       "1  n1               patas_monkey\n",
       "2  n2                bald_uakari\n",
       "3  n3           japanese_macaque\n",
       "4  n4             pygmy_marmoset\n",
       "5  n5      white_headed_capuchin\n",
       "6  n6           silvery_marmoset\n",
       "7  n7     common_squirrel_monkey\n",
       "8  n8  black_headed_night_monkey\n",
       "9  n9             nilgiri_langur"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.DataFrame()\n",
    "labels[\"id\"] = monkey_labels[\"Label\"].str.strip()\n",
    "labels[\"name\"] = monkey_labels[\"Common Name\"].str.strip()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    n0\n",
       "1    n1\n",
       "2    n2\n",
       "3    n3\n",
       "4    n4\n",
       "5    n5\n",
       "6    n6\n",
       "7    n7\n",
       "8    n8\n",
       "9    n9\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map the labels to integers\n",
    "m_id= labels[\"id\"]\n",
    "m_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir(training_data)\n",
    "for entry in entries:\n",
    "    for f in glob.glob(os.path.join(os.path.join(training_data,entry),\"*.jpg\")):\n",
    "        W = 250.\n",
    "        oriimg = cv2.imread(f,cv2.IMREAD_COLOR)\n",
    "        depth = oriimg.shape\n",
    "        imgScale = W/250\n",
    "        newX,newY = 250*imgScale, 250*imgScale\n",
    "        newimg = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "        cv2.imwrite(f,newimg)        \n",
    "\n",
    "entries2 = os.listdir(validation_data)\n",
    "\n",
    "for entry in entries2:\n",
    "    for f in glob.glob(os.path.join(os.path.join(validation_data,entry),\"*.jpg\")):\n",
    "        W = 250.\n",
    "        oriimg = cv2.imread(f,cv2.IMREAD_COLOR)\n",
    "        depth = oriimg.shape\n",
    "        imgScale = W/250\n",
    "        newX,newY = 250*imgScale, 250*imgScale\n",
    "        newimg = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "        cv2.imwrite(f,newimg)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width=250\n",
    "image_height=250\n",
    "batch_size= 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1096 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(training_data, \n",
    "                                                    target_size=(image_width, image_height), \n",
    "                                                    batch_size = batch_size, \n",
    "                                                    shuffle=True, # By shuffling the images we add some randomness and prevent overfitting\n",
    "                                                    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(validation_data, \n",
    "                                                    target_size=(image_width, image_height), \n",
    "                                                    batch_size = batch_size, \n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = 1097\n",
    "validation_samples = 272\n",
    "total_steps = training_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3), pooling=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-5]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f3e83734240> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e83734cf8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e837343c8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f3e83757898> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e83757828> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81ef8a20> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f3e81ea8278> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81f11e80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81ec4da0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81e755f8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f3e81e91d68> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81e91a20> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81e408d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81e5d8d0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f3e81e10898> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81e10400> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81dc4550> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f3e81ddbda0> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f3e81d8d2e8> True\n",
      "<keras.layers.pooling.GlobalMaxPooling2D object at 0x7f3e81d75ef0> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "transfer_model = Sequential()\n",
    "for layer in model.layers:\n",
    "    transfer_model.add(layer)\n",
    "transfer_model.add(Dense(512, activation=\"relu\"))\n",
    "transfer_model.add(Dropout(0.5))\n",
    "transfer_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\n",
    "\n",
    "transfer_model.compile(loss=\"categorical_crossentropy\",\n",
    "                      optimizer=adam,\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nikhil/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/21\n",
      "68/68 [==============================] - 855s 13s/step - loss: 2.2227 - acc: 0.2188 - val_loss: 1.4943 - val_acc: 0.5331\n",
      "Epoch 2/21\n",
      "68/68 [==============================] - 717s 11s/step - loss: 1.2957 - acc: 0.5653 - val_loss: 0.6515 - val_acc: 0.8051\n",
      "Epoch 3/21\n",
      "68/68 [==============================] - 720s 11s/step - loss: 0.8255 - acc: 0.7335 - val_loss: 0.4970 - val_acc: 0.8419\n",
      "Epoch 4/21\n",
      "68/68 [==============================] - 745s 11s/step - loss: 0.5501 - acc: 0.8373 - val_loss: 0.4070 - val_acc: 0.8897\n",
      "Epoch 5/21\n",
      "68/68 [==============================] - 738s 11s/step - loss: 0.4357 - acc: 0.8419 - val_loss: 0.4453 - val_acc: 0.8566\n",
      "Epoch 6/21\n",
      "68/68 [==============================] - 836s 12s/step - loss: 0.3574 - acc: 0.8851 - val_loss: 0.3507 - val_acc: 0.8897\n",
      "Epoch 7/21\n",
      "68/68 [==============================] - 944s 14s/step - loss: 0.3152 - acc: 0.8971 - val_loss: 0.2431 - val_acc: 0.9375\n",
      "Epoch 8/21\n",
      "68/68 [==============================] - 720s 11s/step - loss: 0.2242 - acc: 0.9283 - val_loss: 0.2403 - val_acc: 0.9301\n",
      "Epoch 9/21\n",
      "68/68 [==============================] - 737s 11s/step - loss: 0.2014 - acc: 0.9311 - val_loss: 0.3421 - val_acc: 0.8934\n",
      "Epoch 10/21\n",
      "68/68 [==============================] - 732s 11s/step - loss: 0.2194 - acc: 0.9237 - val_loss: 0.2738 - val_acc: 0.9191\n",
      "Epoch 11/21\n",
      "68/68 [==============================] - 742s 11s/step - loss: 0.1731 - acc: 0.9448 - val_loss: 0.1861 - val_acc: 0.9375\n",
      "Epoch 12/21\n",
      "68/68 [==============================] - 735s 11s/step - loss: 0.1634 - acc: 0.9476 - val_loss: 0.2688 - val_acc: 0.9265\n",
      "Epoch 13/21\n",
      "68/68 [==============================] - 738s 11s/step - loss: 0.1622 - acc: 0.9439 - val_loss: 0.1483 - val_acc: 0.9412\n",
      "Epoch 14/21\n",
      "68/68 [==============================] - 737s 11s/step - loss: 0.1086 - acc: 0.9632 - val_loss: 0.1980 - val_acc: 0.9412\n",
      "Epoch 15/21\n",
      "68/68 [==============================] - 741s 11s/step - loss: 0.1366 - acc: 0.9577 - val_loss: 0.1282 - val_acc: 0.9706\n",
      "Epoch 16/21\n",
      "68/68 [==============================] - 745s 11s/step - loss: 0.1380 - acc: 0.9568 - val_loss: 0.1790 - val_acc: 0.9154\n",
      "Epoch 17/21\n",
      "68/68 [==============================] - 743s 11s/step - loss: 0.1347 - acc: 0.9605 - val_loss: 0.1729 - val_acc: 0.9375\n",
      "Epoch 18/21\n",
      "68/68 [==============================] - 743s 11s/step - loss: 0.0941 - acc: 0.9669 - val_loss: 0.2898 - val_acc: 0.9449\n",
      "Epoch 19/21\n",
      "68/68 [==============================] - 743s 11s/step - loss: 0.0697 - acc: 0.9798 - val_loss: 0.2055 - val_acc: 0.9449\n",
      "Epoch 20/21\n",
      "68/68 [==============================] - 742s 11s/step - loss: 0.0909 - acc: 0.9724 - val_loss: 0.2221 - val_acc: 0.9375\n",
      "Epoch 21/21\n",
      "68/68 [==============================] - 733s 11s/step - loss: 0.0486 - acc: 0.9844 - val_loss: 0.1654 - val_acc: 0.9559\n"
     ]
    }
   ],
   "source": [
    "model_history = transfer_model.fit_generator(train_generator, steps_per_epoch=training_samples // batch_size,\n",
    "                                            epochs=21,\n",
    "                                            validation_data=validation_generator,\n",
    "                                            validation_steps=validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
